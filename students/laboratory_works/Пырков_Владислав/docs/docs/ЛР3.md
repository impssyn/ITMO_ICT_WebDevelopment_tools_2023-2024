# Лабораторная раб. 3

## Ход выполнения

### Dockerfile для lab_1

```
FROM python:3.10-alpine3.19

WORKDIR /lab_1

COPY . .
RUN pip3 install -r requirements.txt

CMD uvicorn main:app --host localhost --port 8000
```

### Dockerfile для lab_2

```
FROM python:3.10-alpine3.19

WORKDIR /lab_2

COPY . .
RUN pip3 install -r requirements.txt

CMD uvicorn main:app --host localhost --port 8001
```

### docker-compose.yaml
```
version: '3.10'
services:

  lab_1:
    container_name: lab_1
    build:
      context: ./lab_1
    env_file: .env
    depends_on:
      - db
    ports:
      - "8000:8000"
    command: uvicorn main:app --host 0.0.0.0 --port 8000
    networks:
      - backend_3
    restart: always

  lab_2:
    container_name: lab_2
    build:
      context: ./lab_2
    env_file: .env
    restart: always
    ports:
      - "8001:8001"
    command: uvicorn main:app --host 0.0.0.0 --port 8001
    depends_on:
      - redis
      - db
    networks:
      - backend_3

  celery:
    build:
      context: ./lab_2
    container_name: celery
    command: celery -A celery_start worker --loglevel=info
    restart: always
    depends_on:
      - redis
      - lab_2
      - db
    networks:
      - backend_3

  redis:
    image: redis
    ports:
      - "6379:6379"
    networks:
      - backend_3
    depends_on:
      - db

  db:
    image: postgres
    restart: always
    environment:
      - POSTGRES_PASSWORD=Bakugan102!
      - POSTGRES_USER=postgres
      - POSTGRES_DB=test_db
    volumes:
      - postgres_data:/var/lib/postgresql/data/
    ports:
      - "5432:5432"
    networks:
      - backend_3


volumes:
  postgres_data:

networks:
  backend_3:
     driver: bridge
```

### celery_main.py

```
from celery import Celery

celery_app = Celery(
    "worker",
    broker="redis://redis:6379/0",
    backend="redis://redis:6379/0",
)

celery_app.conf.update(
    task_routes={
        "parse.parse_and_save": "main-queue",
    },
)
```

### parse.py

```
import requests
from bs4 import BeautifulSoup
from celery_main import celery_app
import psycopg2

def get_db_connection():
    return psycopg2.connect(
        dbname='test_db',
        user='postgres',
        password='Bakugan102!',
        host='db',
        port='5432'
    )

def insert_data(url, title):
    conn = get_db_connection()
    cur = conn.cursor()

    cur.execute('''INSERT INTO "site" (url, title) VALUES (%s, %s)
    ''', (url, title))
    conn.commit()
    cur.close()
    conn.close()

@celery_app.task
def parse_and_save(url):
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')
    title = soup.find('title').text
    insert_data(url, title)
```

### main.py в lab_2
```
from fastapi import FastAPI, BackgroundTasks
from parse import parse_and_save
app = FastAPI()


@app.post("/parse/")
async def parse(url: str, background_tasks: BackgroundTasks):
    background_tasks.add_task(parse_and_save, url)
    return {"message": "Parse started."}
```
